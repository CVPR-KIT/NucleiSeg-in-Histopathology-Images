log = "log/"

[Debug]
debug = "True"                                 # Debug Mode - True or False: Radically reduces the dataset size for faster training
debugDilution = 20                            # Debug Dilution - 1/nth of the dataset will be used for training
wandb = "False"                                 # Wandb Logging

[Stain Normalization]
normalization = "None"                       # Normalization Avl: macenko, reinhard, None
targetImagePath = "/mnt/BishalFiles/MoNuSeg/Dataset/Training/TissueImages/TCGA-A7-A13F-01Z-00-DX1.png" # Target Image for Normalization


[Image Augmentation]
to_be_aug = "/mnt/BishalFiles/MoNuSeg/Dataset/"     # Data That is to be augmenated  - shouls contain Test and Training directories
out_dir = "/mnt/BishalFiles/MoNuSeg/Dataset/slidingAug/"         # Output for Sliding Window Augmentation
augmented_dir = "/mnt/BishalFiles/MoNuSeg/Dataset/augmentated/"              # Output for Augmentation

tileHeight = 800                               # Sliding Window height
tileWidth = 800                                # Sliding Window Width
slidingSize = 50                                # Slide Skipping size
augmentPerImage = 100                           # Number of augmentation to perform per image that was generated using sliding down
finalTileHeight = 256                           # Final Height of augmenated image
finalTileWidth = 256                            # Final Width of augmenated image

[Train-Val split]
splitRatio = 0.9                                # 0.8 -> 80% training 20% validation

[Training]
trainDataset = "/mnt/BishalFiles/MoNuSeg/train/"                    # Images to be during Training
valDataset = "/mnt/BishalFiles/MoNuSeg/val/"                        # Images to used during Validation
testDataset = "/mnt/BishalFiles/MoNuSeg/test/"                      # Images to used during Testing

resumeModel = "model/best_model.pth"            # Model to used during re-training

sampleImages = "False"                           # Sample Images during Training
reUseFeatures = "False"                         # Use existing features - Should re-train features if dataset is changed

[Class Config]
class1 = "0, 0, 0"                          #black
class2 = "255, 255, 255"                         #white

[Model]
model_type = "UNet_3PlusShort"                           # Model Avl: UNet ,UNet_3Plus, EluNet, UNet_3PlusShort

[Parameters]
input_img_type = "rgb"                          # Input Image Type: rgb, gray
kernel_size = 3
use_maxblurpool = "False"                       # Use MaxBlurPool
epochs = 50
batch_size = 16
learning_rate = 0.000001                         # can be set to "auto" for finding the best learning rate or set to 0.00001
lr_decay = "False"                             # Learning Rate Decay  - True or False
num_classes = 2
weight_path = "None"
activation = "relu"                             # Activations available:
resume = "False"                                # Resume Training
resume_epoch = 0                                # Resume Training from epoch
channel = 16                                    # Default: 16 Can be set to 64 or other
attention = "False"                             # Model 1 only
loss = "dice"                           # Losses available: bce, jaccard, focal, pwcel, dice, weighteddice, unet3+loss, improvedLoss, ClassRatioLoss, RBAF, focalDiceLoss
dropout = 0                                   # Dropout rate
dropoutLOC = "std"                              # Dropout Location: std, after (after 20 iterations)
dilation = 1                                    # For Dilated convolution.
l1_regularization = "False"                     # L1 Regularization